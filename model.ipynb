{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Use Case: ZAF043 Crowd Anomaly Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1 - Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "is_executing": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Frames Shape: (6,)\n",
      "Training Labels Shape: (6,)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def load_training_data(directory):\n",
    "    # Initialize lists for frames and labels\n",
    "    frames = []\n",
    "    labels = []\n",
    "\n",
    "    # Iterate over the files in the directory\n",
    "    for filename in os.listdir(directory):\n",
    "        # Get the full file path\n",
    "        file_path = os.path.join(directory, filename)\n",
    "\n",
    "        # Load the frame using OpenCV\n",
    "        frame = cv2.imread(file_path)\n",
    "\n",
    "        # Preprocess the frame if needed\n",
    "\n",
    "        # Append the frame to the frames list\n",
    "        frames.append(frame)\n",
    "\n",
    "        # Extract the label from the filename (assuming the filename contains the label information)\n",
    "        label = filename.split(\"_\")[0]  # Extract the label from the filename based on the naming convention\n",
    "        labels.append(label)\n",
    "\n",
    "    # Convert frames and labels to numpy arrays\n",
    "    frames = np.array(frames)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    return frames, labels\n",
    "\n",
    "# Directory path containing the training data\n",
    "training_data_directory = \"D:\\\\Data Set\\\\Crowd Anomaly Detection\\\\UCSD_Anomaly_Dataset\"\n",
    "\n",
    "# Load training data\n",
    "training_frames, training_labels = load_training_data(training_data_directory)\n",
    "\n",
    "# Print the shape of the training frames and labels\n",
    "print(\"Training Frames Shape:\", training_frames.shape)\n",
    "print(\"Training Labels Shape:\", training_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2 - Data Preprocessing, Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def extract_features(frames):\n",
    "    features = []\n",
    "    \n",
    "    # Convert frames to grayscale\n",
    "    gray_frames = [cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) for frame in frames]\n",
    "    \n",
    "    # Calculate optical flow for consecutive frames\n",
    "    for i in range(len(frames) - 1):\n",
    "        prev_frame = gray_frames[i]\n",
    "        next_frame = gray_frames[i + 1]\n",
    "        \n",
    "        # Compute optical flow using Lucas-Kanade method\n",
    "        flow = cv2.calcOpticalFlowFarneback(prev_frame, next_frame, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "        \n",
    "        # Extract relevant features from the optical flow\n",
    "        # Example: Compute the mean and standard deviation of the flow vectors\n",
    "        mean_flow = np.mean(flow)\n",
    "        std_flow = np.std(flow)\n",
    "        \n",
    "        # Append the extracted features to the list\n",
    "        features.append([mean_flow, std_flow])\n",
    "    \n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 3 - Models\n",
    "In this code, the train_mdt_model() function takes features (the extracted features) and num_components (the number of components in the MDT model) as inputs. It initializes a Gaussian Mixture Model (GMM) with n_components=num_components and fits it to the features using the fit() method. The trained model is then returned.\n",
    "The scikit-learn library installed (pip install scikit-learn) before running this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "def train_mdt_model(features, num_components):\n",
    "    # Convert the list of features into a 3D numpy array\n",
    "    features_array = np.array(features)\n",
    "    \n",
    "    # Get the shape of the array\n",
    "    num_samples, num_frames, num_features = features_array.shape\n",
    "    \n",
    "    # Reshape the array to have two dimensions\n",
    "    features_2d = features_array.reshape(num_samples * num_frames, num_features)\n",
    "    \n",
    "    # Train a Gaussian Mixture Model (GMM) on the extracted features\n",
    "    gmm = GaussianMixture(n_components=num_components)\n",
    "    gmm.fit(features_2d)\n",
    "    \n",
    "    return gmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_anomaly_score(observation, model):\n",
    "    # Compute the anomaly score by comparing the observation with the learned model\n",
    "    score = -model.score_samples(observation.reshape(1, -1))\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of frames: 7000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tifffile\n",
    "\n",
    "# Specify the directory path containing the frames\n",
    "directories =[\n",
    "    r\"D:\\Data Set\\Crowd Anomaly Detection\\UCSD_Anomaly_Dataset\\UCSDped1\\Train\\Train001\",\n",
    "    r\"D:\\Data Set\\Crowd Anomaly Detection\\UCSD_Anomaly_Dataset\\UCSDped1\\Train\\Train002\",\n",
    "    r\"D:\\Data Set\\Crowd Anomaly Detection\\UCSD_Anomaly_Dataset\\UCSDped1\\Train\\Train003\",\n",
    "    r\"D:\\Data Set\\Crowd Anomaly Detection\\UCSD_Anomaly_Dataset\\UCSDped1\\Train\\Train004\",\n",
    "    r\"D:\\Data Set\\Crowd Anomaly Detection\\UCSD_Anomaly_Dataset\\UCSDped1\\Train\\Train005\",\n",
    "    r\"D:\\Data Set\\Crowd Anomaly Detection\\UCSD_Anomaly_Dataset\\UCSDped1\\Train\\Train006\",\n",
    "    r\"D:\\Data Set\\Crowd Anomaly Detection\\UCSD_Anomaly_Dataset\\UCSDped1\\Train\\Train007\",\n",
    "    r\"D:\\Data Set\\Crowd Anomaly Detection\\UCSD_Anomaly_Dataset\\UCSDped1\\Train\\Train008\",\n",
    "    r\"D:\\Data Set\\Crowd Anomaly Detection\\UCSD_Anomaly_Dataset\\UCSDped1\\Train\\Train009\",\n",
    "    r\"D:\\Data Set\\Crowd Anomaly Detection\\UCSD_Anomaly_Dataset\\UCSDped1\\Train\\Train010\",\n",
    "    r\"D:\\Data Set\\Crowd Anomaly Detection\\UCSD_Anomaly_Dataset\\UCSDped1\\Train\\Train011\",\n",
    "    r\"D:\\Data Set\\Crowd Anomaly Detection\\UCSD_Anomaly_Dataset\\UCSDped1\\Train\\Train012\",\n",
    "    r\"D:\\Data Set\\Crowd Anomaly Detection\\UCSD_Anomaly_Dataset\\UCSDped1\\Train\\Train013\",\n",
    "    r\"D:\\Data Set\\Crowd Anomaly Detection\\UCSD_Anomaly_Dataset\\UCSDped1\\Train\\Train014\",\n",
    "    r\"D:\\Data Set\\Crowd Anomaly Detection\\UCSD_Anomaly_Dataset\\UCSDped1\\Train\\Train015\",\n",
    "    r\"D:\\Data Set\\Crowd Anomaly Detection\\UCSD_Anomaly_Dataset\\UCSDped1\\Train\\Train016\",\n",
    "    r\"D:\\Data Set\\Crowd Anomaly Detection\\UCSD_Anomaly_Dataset\\UCSDped1\\Train\\Train017\",\n",
    "    r\"D:\\Data Set\\Crowd Anomaly Detection\\UCSD_Anomaly_Dataset\\UCSDped1\\Train\\Train018\",\n",
    "    r\"D:\\Data Set\\Crowd Anomaly Detection\\UCSD_Anomaly_Dataset\\UCSDped1\\Train\\Train019\",\n",
    "    r\"D:\\Data Set\\Crowd Anomaly Detection\\UCSD_Anomaly_Dataset\\UCSDped1\\Train\\Train020\",\n",
    "    r\"D:\\Data Set\\Crowd Anomaly Detection\\UCSD_Anomaly_Dataset\\UCSDped1\\Train\\Train020\",\n",
    "    r\"D:\\Data Set\\Crowd Anomaly Detection\\UCSD_Anomaly_Dataset\\UCSDped1\\Train\\Train021\",\n",
    "    r\"D:\\Data Set\\Crowd Anomaly Detection\\UCSD_Anomaly_Dataset\\UCSDped1\\Train\\Train022\",\n",
    "    r\"D:\\Data Set\\Crowd Anomaly Detection\\UCSD_Anomaly_Dataset\\UCSDped1\\Train\\Train023\",\n",
    "    r\"D:\\Data Set\\Crowd Anomaly Detection\\UCSD_Anomaly_Dataset\\UCSDped1\\Train\\Train024\",\n",
    "    r\"D:\\Data Set\\Crowd Anomaly Detection\\UCSD_Anomaly_Dataset\\UCSDped1\\Train\\Train025\",\n",
    "    r\"D:\\Data Set\\Crowd Anomaly Detection\\UCSD_Anomaly_Dataset\\UCSDped1\\Train\\Train026\",\n",
    "    r\"D:\\Data Set\\Crowd Anomaly Detection\\UCSD_Anomaly_Dataset\\UCSDped1\\Train\\Train027\",\n",
    "    r\"D:\\Data Set\\Crowd Anomaly Detection\\UCSD_Anomaly_Dataset\\UCSDped1\\Train\\Train028\",\n",
    "    r\"D:\\Data Set\\Crowd Anomaly Detection\\UCSD_Anomaly_Dataset\\UCSDped1\\Train\\Train029\",\n",
    "    r\"D:\\Data Set\\Crowd Anomaly Detection\\UCSD_Anomaly_Dataset\\UCSDped1\\Train\\Train030\",\n",
    "    r\"D:\\Data Set\\Crowd Anomaly Detection\\UCSD_Anomaly_Dataset\\UCSDped1\\Train\\Train031\",\n",
    "    r\"D:\\Data Set\\Crowd Anomaly Detection\\UCSD_Anomaly_Dataset\\UCSDped1\\Train\\Train032\",\n",
    "    r\"D:\\Data Set\\Crowd Anomaly Detection\\UCSD_Anomaly_Dataset\\UCSDped1\\Train\\Train033\",\n",
    "    r\"D:\\Data Set\\Crowd Anomaly Detection\\UCSD_Anomaly_Dataset\\UCSDped1\\Train\\Train034\"\n",
    "    \n",
    "]\n",
    "# Initialize an empty list to store the frames\n",
    "frames = []\n",
    "\n",
    "# Iterate over the directories\n",
    "for directory_path in directories:\n",
    "    # Iterate over the files in the directory\n",
    "    for filename in os.listdir(directory_path):\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "\n",
    "        # Check if the file is a .tif image\n",
    "        if filename.endswith(\".tif\"):\n",
    "            # Read the frame using tifffile\n",
    "            frame = tifffile.imread(file_path)\n",
    "\n",
    "            # Append the frame to the list\n",
    "            frames.append(frame)\n",
    "\n",
    "# Print the number of frames loaded\n",
    "print(\"Number of frames:\", len(frames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize variables\n",
    "num_components = 10  # Number of components in the MDT model\n",
    "features = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(frames):\n",
    "    features = []\n",
    "\n",
    "    # Calculate optical flow for consecutive frames\n",
    "    for i in range(len(frames) - 1):\n",
    "        frame1 = frames[i]\n",
    "        frame2 = frames[i + 1]\n",
    "\n",
    "        # Calculate optical flow\n",
    "        flow = cv2.calcOpticalFlowFarneback(frame1, frame2, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "\n",
    "        # Flatten the flow matrix and append it to the features\n",
    "        flow_flat = flow.reshape(-1)\n",
    "        features.append(flow_flat)\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store the features\n",
    "features = []\n",
    "\n",
    "# Iterate over the frames and extract features\n",
    "for frame in frames:\n",
    "    # Preprocess frame if needed\n",
    "    # Extract features from the frame\n",
    "    frame_features = extract_features(frame)\n",
    "    features.append(frame_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert features to numpy array\n",
    "features = np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Convert the list of features into a 3D numpy array\n",
    "features_array = np.array(features)\n",
    "\n",
    "# Get the shape of the array\n",
    "num_samples, num_frames, num_features = features_array.shape\n",
    "\n",
    "# Reshape the array to have two dimensions\n",
    "features_2d = features_array.reshape(num_samples * num_frames, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train MDT model\n",
    "mdt_model = train_mdt_model(features, num_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'extract_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m     exit()\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Extract features from the new frame\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m new_features \u001b[38;5;241m=\u001b[39m \u001b[43mextract_features\u001b[49m([new_frame])  \u001b[38;5;66;03m# Pass the new frame as a list to the extract_features function\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Check if the features are extracted successfully\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(new_features) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'extract_features' is not defined"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the new frame using OpenCV\n",
    "new_frame = cv2.imread(\"D:/Data Set/Crowd Anomaly Detection/UCSD_Anomaly_Dataset/UCSDped1/Test/Test034/023.tif\")\n",
    "\n",
    "# Check if the new frame is loaded successfully\n",
    "if new_frame is None:\n",
    "    print(\"Failed to load the new frame.\")\n",
    "    exit()\n",
    "\n",
    "# Extract features from the new frame\n",
    "new_features = extract_features([new_frame])  # Pass the new frame as a list to the extract_features function\n",
    "\n",
    "# Check if the features are extracted successfully\n",
    "if len(new_features) == 0:\n",
    "    print(\"Failed to extract features from the new frame.\")\n",
    "    exit()\n",
    "\n",
    "# Convert the features to a numpy array\n",
    "new_features = np.array(new_features)\n",
    "\n",
    "# Reshape the features for prediction\n",
    "new_observation = new_features.reshape(1, -1)\n",
    "\n",
    "# Compute anomaly score for the new observation\n",
    "anomaly_score = compute_anomaly_score(new_observation, mdt_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Anomaly Score:\", anomaly_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### *Conclusion:* \n",
    "Based on the provided code and information, the recommended model for anomaly detection in crowd behavior is the MDT (Motion Density Texture) model trained using Gaussian Mixture Model (GMM). This model utilizes optical flow features extracted from consecutive frames to learn patterns and detect anomalies in crowd behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 4 - Saving the model\n",
    "Save the DS best model in the Jupyter notebook `model.ipynb` in the following formats:\n",
    "\n",
    "- `network.save('model.h5')` #keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mdt_model.save('model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
